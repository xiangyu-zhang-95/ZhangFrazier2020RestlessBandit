{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "import numpy as np\n",
    "import time\n",
    "from gurobipy import *\n",
    "import collections\n",
    "\n",
    "class fluid_model():\n",
    "    def p(self, s, a, sprime):\n",
    "        if a == 0:\n",
    "            return s == sprime\n",
    "        if a == 1:\n",
    "            tmp_a, tmp_b = s[0], s[1]\n",
    "            tmp_c, tmp_d = sprime[0], sprime[1]\n",
    "            if tmp_a == tmp_c and tmp_b + 1 == tmp_d:\n",
    "                return 1 - (tmp_a + 1)/(tmp_a + tmp_b + 2)\n",
    "            if tmp_a + 1 == tmp_c and tmp_b == tmp_d:\n",
    "                return (tmp_a + 1)/(tmp_a + tmp_b + 2)\n",
    "            return 0\n",
    "    \n",
    "    def reward(self, s, a):\n",
    "        if a == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return (s[0] + 1)/(s[0] + s[1] + 2)\n",
    "    def __init__(self, T, alphas):\n",
    "        self.alphas = alphas\n",
    "        self.T = T\n",
    "        self.m, self.x, self.y, self.z = None, {}, {}, {}\n",
    "        self.duals = None\n",
    "        self.A, self.B, self.C = set(), set(), set()\n",
    "\n",
    "    def __LP_sol(self, T, alphas):\n",
    "        \n",
    "        time = [t for t in range(T)]\n",
    "        win = [i for i in range(T)]\n",
    "        los = [j for j in range(T)]\n",
    "        d_var, reward = multidict({(t, i, j): (i+1)/(i+j+2) \\\n",
    "                                    for t in time \\\n",
    "                                        for i in win \\\n",
    "                                            for j in los})\n",
    "        m = Model(\"MAB\")\n",
    "        n = m.addVars(time, win, los, name = \"n\")\n",
    "        x = m.addVars(time, win, los, name = \"x\")\n",
    "        \n",
    "        # set ojective\n",
    "        m.setObjective(sum(x[t, i, j] * reward[(t, i, j)] \\\n",
    "                            for t in time for i in win \\\n",
    "                                for j in los), GRB.MAXIMIZE)\n",
    "        \n",
    "        # add resource constraint\n",
    "        m.addConstrs(sum(x[t, i, j] for i in win for j in los) \\\n",
    "                        == alphas[t] for t in time)\n",
    "        \n",
    "        # add initial constraint\n",
    "        m.addConstr(n[0, 0, 0] == 1)\n",
    "        m.addConstr(sum(n[0, i, j] for i in win for j in los) == 1)\n",
    "        \n",
    "        # add x constraint\n",
    "        m.addConstrs(x[t, i, j] <= n[t, i, j] for t in time for i in win for j in los)\n",
    "        m.addConstrs(x[t, i, j] >= 0 for t in time for i in win for j in los)\n",
    "        \n",
    "        # add fluid balance\n",
    "        m.addConstrs(n[t, i, j] - x[t-1, i-1, j]*reward[(t-1, i-1, j)] - x[t-1, i, j-1]*(1-reward[(t-1, i, j-1)]) - (n[t-1, i, j] - x[t-1, i, j]) == 0 \n",
    "                    for t in range(1, T) for i in range(1, T) for j in range(1, T))\n",
    "        m.addConstrs(n[t, 0, j] - x[t-1, 0, j-1]*(1-reward[(t-1, 0, j-1)]) - (n[t-1, 0, j] - x[t-1, 0, j])== 0 \n",
    "                    for t in range(1, T) for j in range(1, T))\n",
    "        m.addConstrs(n[t, i, 0] - x[t-1, i-1, 0]*reward[(t-1, i-1, 0)] - (n[t-1, i, 0] - x[t-1, i, 0]) == 0\n",
    "                    for t in range(1, T) for i in range(1, T))\n",
    "        m.addConstrs(n[t, 0, 0] - (n[t-1, 0, 0] - x[t-1, 0, 0]) == 0 for t in range(1, T))\n",
    "        m.setParam('OutputFlag', False)\n",
    "        m.optimize()\n",
    "        print('Obj: %g' % m.objVal)\n",
    "        self.objVal = m.objVal\n",
    "        \n",
    "        return m\n",
    "\n",
    "    def __solve(self, method=1):\n",
    "        setParam(\"Method\", method)\n",
    "        T = self.T\n",
    "        m = self.__LP_sol(self.T, self.alphas)\n",
    "        self.m = m\n",
    "        self.duals = m.PI[0: T]\n",
    "        \n",
    "        self.sorted = {t: [(a, b) for a in range(T) for b in range(T) if a + b <= t] for t in range(T)}\n",
    "        v = {}\n",
    "        for t in range(T - 1, -1, -1):\n",
    "            advantage = {(a, b): 0 for a in range(T) for b in range(T) if a + b <= t}\n",
    "            for a in range(T):\n",
    "                for b in range(T):\n",
    "                    if a + b <= t:\n",
    "                        if t == T - 1:\n",
    "                            r_pull = self.reward((a, b), 1) - self.duals[t]\n",
    "                            r_idle = 0\n",
    "                        else:\n",
    "                            r_pull = self.reward((a, b), 1) - self.duals[t] + \\\n",
    "                                     self.p((a, b), 1, (a + 1, b)) * v[t + 1, (a + 1, b)] + \\\n",
    "                                     self.p((a, b), 1, (a, b + 1)) * v[t + 1, (a, b + 1)]\n",
    "                            r_idle = v[t + 1, (a, b)]\n",
    "                        advantage[(a, b)] = r_pull - r_idle\n",
    "                        if r_pull < r_idle:\n",
    "                            v[(t, (a, b))] = r_idle\n",
    "                            continue\n",
    "                        v[(t, (a, b))] = r_pull\n",
    "            self.sorted[t].sort(reverse=True, key=lambda x: advantage[x])\n",
    "        \n",
    "        self.z[(0, (0, 0))] = 1\n",
    "        self.pull_reward = 0\n",
    "        for t in range(T):\n",
    "            resource = self.alphas[t]\n",
    "            for a, b in self.sorted[t]:\n",
    "                self.x[(t, (a, b))] = min(self.z[(t, (a, b))], resource)\n",
    "                self.pull_reward += self.x[(t, (a, b))] * self.reward((a, b), 1)\n",
    "                self.y[(t, (a, b))] = self.z[(t, (a, b))] - self.x[(t, (a, b))]\n",
    "                resource = resource - self.x[(t, (a, b))]\n",
    "            if t == T - 1:\n",
    "                continue\n",
    "            for a, b in self.sorted[t + 1]:\n",
    "                self.z[(t + 1, (a, b))] = (self.y[(t, (a, b))] if a + b <= t else 0) + \\\n",
    "                                          a / (a + b + 1) * (self.x[(t, (a - 1, b))] if a >= 1 else 0) + \\\n",
    "                                          b / (a + b + 1) * (self.x[(t, (a, b - 1))] if b >= 1 else 0)\n",
    "    \n",
    "    def calculate_occupation_measure_and_classify_state(self, epsilon=10**(-6)):\n",
    "        self.__solve()\n",
    "        m, sol, T = self.m, dict(), self.T\n",
    "\n",
    "        for key in self.z:\n",
    "            if self.x[key] > epsilon and self.y[key] < epsilon:\n",
    "                self.A.add(key)\n",
    "                continue\n",
    "            if self.x[key] > epsilon and self.y[key] > epsilon:\n",
    "                self.B.add(key)\n",
    "                continue\n",
    "            if self.x[key] < epsilon and self.y[key] > epsilon:\n",
    "                self.C.add(key)\n",
    "                continue\n",
    "        return\n",
    "    \n",
    "    def check_degeneracy(self):\n",
    "        if sorted([key[0] for key in self.B]) == [i for i in range(self.T)] and \\\n",
    "                    abs(self.objVal - self.pull_reward) < 10**(-13):\n",
    "            print(f\"\"\"\n",
    "            Model objective: {self.pull_reward}, different from {self.objVal} (solution from LP) less than 10e-15.\n",
    "            Model is non-degenerate.\n",
    "            \"\"\")\n",
    "        else:\n",
    "            raise Exception(\"Model is degenerate.\\n\")\n",
    "\n",
    "    def calculate_diffusion_index(self, epsilon=10**(-8)):\n",
    "        self.calculate_occupation_measure_and_classify_state()\n",
    "        x, y, z, T = self.x, self.y, self.z, self.T\n",
    "        v = {(t, (a, b)): 0 for t in range(T + 1) for a in range(t + 1) for b in range(t + 1) if a + b <= t}\n",
    "        diffusion_index = {(t, (a, b)): 0 for t in range(T) for a in range(t + 1) for b in range(t + 1) if a + b <= t}\n",
    "\n",
    "        for t in range(T - 1, -1, -1):\n",
    "            state_t = [(a, b) for a in range(t + 1) for b in range(t + 1) if a + b <= t]\n",
    "            for s in state_t:\n",
    "                s_w = (s[0] + 1, s[1]) # state after win\n",
    "                s_l = (s[0], s[1] + 1) # state after loss\n",
    "                diffusion_index[(t, s)] = self.reward(s, 1) + self.p(s, 1, s_w)*v[(t + 1, s_w)] \\\n",
    "                                          + self.p(s, 1, s_l)*v[(t + 1, s_l)] \\\n",
    "                                          - self.reward(s, 0) - self.p(s, 0, s)*v[(t + 1, s)]\n",
    "            \n",
    "            l_y_g_0 = [(diffusion_index[(t, s)], s) for s in state_t if self.x[(t, s)] > epsilon]\n",
    "\n",
    "            _, sbar = min(l_y_g_0)\n",
    "            for s in state_t:\n",
    "                if (t, s) in self.A:\n",
    "                    v[(t, s)]= diffusion_index[(t, s)] - diffusion_index[(t, sbar)] + v[(t + 1, s)]\n",
    "                else:\n",
    "                    v[(t, s)] = self.reward(s, 0) + v[(t + 1, s)]\n",
    "        self.diffusion_index = diffusion_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "class State():\n",
    "    count = {}\n",
    "    number = None\n",
    "    t = None\n",
    "\n",
    "    def __init__(self, t):\n",
    "            self.count = {(a, b): 0 for a in range(t + 1) \\\n",
    "                            for b in range(t + 1) if a + b <= t}\n",
    "            self.number = 0\n",
    "            self.t = t\n",
    "\n",
    "\n",
    "def initialize(N):\n",
    "    state = State(t=0)\n",
    "    state.number = N\n",
    "    state.count = {(0, 0): N}\n",
    "    return state\n",
    "\n",
    "def model_paras(model):\n",
    "    alphas = model.alphas\n",
    "    A = model.A\n",
    "    B = model.B\n",
    "    C = model.C\n",
    "    diffusion_index = model.diffusion_index\n",
    "    T = model.T\n",
    "    paras = (alphas, A, B, C, diffusion_index, T)\n",
    "    return paras\n",
    "    \n",
    "\n",
    "def pull(state, paras, use_A_B_C=True):\n",
    "    alphas, A, B, C, diffusion_index, T = paras[0], paras[1], paras[2], paras[3], paras[4], paras[5]\n",
    "    t = state.t\n",
    "    \n",
    "    budget = int(alphas[t] * state.number)\n",
    "    pull_state = {s: 0 for s in state.count}\n",
    "    \n",
    "    if use_A_B_C:\n",
    "        state_A = [s for s in state.count if (t, s) in A]\n",
    "        state_B = [s for s in state.count if (t, s) in B]\n",
    "        state_C = [s for s in state.count if (t, s) in C]\n",
    "\n",
    "        state_A.sort(key=lambda s: diffusion_index[(t, s)], \n",
    "                     reverse=True)\n",
    "        state_B.sort(key=lambda s: diffusion_index[(t, s)], \n",
    "                     reverse=True)\n",
    "        state_C.sort(key=lambda s: diffusion_index[(t, s)], \n",
    "                     reverse=True)\n",
    "\n",
    "        for H in [state_A, state_B, state_C]:\n",
    "            for s in H:\n",
    "                if state.count[s] <= budget:\n",
    "                    pull_state[s] = state.count[s]\n",
    "                    budget -= state.count[s]\n",
    "                else:\n",
    "                    pull_state[s] = budget\n",
    "                    budget = 0\n",
    "        return pull_state\n",
    "    \n",
    "    state_now = [s for s in state.count]\n",
    "    state_now.sort(key=lambda state: diffusion_index[(t, state)], reverse=True)\n",
    "    for s in state_now:\n",
    "        if state.count[s] <= budget:\n",
    "            pull_state[s] = state.count[s]\n",
    "            budget -= state.count[s]\n",
    "        else:\n",
    "            pull_state[s] = budget\n",
    "            budget = 0\n",
    "    return pull_state\n",
    "\n",
    "\n",
    "def proceed(state, pull_state):\n",
    "    next_state = State(state.t + 1)\n",
    "    next_state.number = state.number\n",
    "    for s in pull_state:\n",
    "            a, b = s[0], s[1]\n",
    "            pull_s = pull_state[s]\n",
    "            total_s = state.count[s]\n",
    "            theta = (a + 1) / (a + b + 2)\n",
    "            success = np.random.binomial(pull_s, theta)\n",
    "            failure = pull_s - success\n",
    "            idle = total_s - pull_s\n",
    "            next_state.count[(a + 1, b)] += success\n",
    "            next_state.count[(a, b)] += idle\n",
    "            next_state.count[(a, b + 1)] += failure\n",
    "    return next_state\n",
    "\n",
    "\n",
    "def reward_generate(pull_state):\n",
    "    tmp = [pull_state[s] * (s[0] + 1)/(s[0] + s[1] + 2) for s in pull_state]\n",
    "    return np.sum(tmp)\n",
    "\n",
    "def simulate(N, paras, use_A_B_C=True):\n",
    "    alphas, A, B, C, diffusion_index, T = paras[0], paras[1], paras[2], paras[3], paras[4], paras[5]\n",
    "    state = initialize(N)\n",
    "    total_reward = 0\n",
    "    for _ in range(T):\n",
    "        pull_state = pull(state, paras, use_A_B_C=use_A_B_C)\n",
    "        total_reward += reward_generate(pull_state)\n",
    "        state = proceed(state, pull_state)\n",
    "    return total_reward\n",
    "\n",
    "def batch_simulate(N, paras, use_A_B_C, rounds):\n",
    "    np.random.seed(os.getpid())\n",
    "    start = time.time()\n",
    "    rewards = [simulate(N, paras, use_A_B_C) for _ in range(rounds)]\n",
    "    end = time.time()\n",
    "    mean = np.mean(rewards)\n",
    "    std = np.std(rewards)\n",
    "    comp_time = end - start\n",
    "    return N, rounds, mean, std, comp_time\n",
    "\n",
    "def wrapper(args):\n",
    "    return batch_simulate(*args)\n",
    "\n",
    "def parallel_simulation(N, model, n_proc, use_A_B_C, rounds):\n",
    "    args = (N, model_paras(model), use_A_B_C)\n",
    "    with Pool(n_proc) as p:\n",
    "        res = p.map(wrapper, [(*args, rounds) for _ in range(n_proc)])\n",
    "    m = rounds * n_proc\n",
    "    mean = np.mean([item[2] for item in res])\n",
    "    std = np.sqrt(np.sum([rounds * item[3] ** 2 for item in res])) / (n_proc * rounds)\n",
    "    comp_time = np.max([item[-1] for item in res])\n",
    "    opt_gap = model.pull_reward * N - mean\n",
    "    return opt_gap, N, m, mean, std, comp_time\n",
    "\n",
    "def fluid_priority_simulation(N, model, use_A_B_C, rounds=1000):\n",
    "    n_proc = int(N * 50 / rounds) + 1\n",
    "    return parallel_simulation(N, model, n_proc, use_A_B_C, rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def create_file(model, file_name, start=150, end=38400):\n",
    "    if os.path.exists(file_name):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(index=[\"opt-gap\", \"N\", \"M\", \"expect-reward\", \"std\", \"time\"])\n",
    "    df.to_csv(file_name, index=True)\n",
    "    N = start\n",
    "    while N <= end:\n",
    "        # res = [opt_gap, N, m, mean, std, comp_time]\n",
    "        res = fluid_priority_simulation(N, model, use_A_B_C=False, rounds=1000)\n",
    "        df[N] = res\n",
    "        df.to_csv(file_name, index=True)\n",
    "        print(f\"N: {N} finished. {df[N]}\")\n",
    "        N = N * 2\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def experiment(T):\n",
    "    number_of_arms = []\n",
    "    horizon = T\n",
    "    gaps, stds = [], []\n",
    "    model = fluid_model(T=horizon, alphas=[1/3]*horizon)\n",
    "    model.calculate_diffusion_index()\n",
    "    model.check_degeneracy()\n",
    "\n",
    "    create_file(model, f\"fp-{horizon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file /home/xz556/gurobi.lic\n",
      "Academic license - for non-commercial use only\n",
      "Changed value of parameter Method to 1\n",
      "   Prev: -1  Min: -1  Max: 5  Default: -1\n",
      "Obj: 4.81431\n",
      "\n",
      "            Model objective: 4.814311826391183, different from 4.814311826391183 (solution from LP) less than 10e-15.\n",
      "            Model is non-degenerate.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "experiment(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
